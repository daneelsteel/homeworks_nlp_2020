{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сравнение качества POS-теггеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ячейка для импортов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Эрнеста\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Эрнеста\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-18 23:06:32,994 https://nlp.informatik.hu-berlin.de/resources/models/multi-pos/pos-multi-v0.1.pt not found in cache, downloading to C:\\Users\\BCD4~1\\AppData\\Local\\Temp\\tmprxgk6up2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 314055714/314055714 [00:39<00:00, 7955618.55B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-18 23:07:12,719 copying C:\\Users\\BCD4~1\\AppData\\Local\\Temp\\tmprxgk6up2 to cache at C:\\Users\\Эрнеста\\.flair\\models\\pos-multi-v0.1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-18 23:07:14,084 removing temp file C:\\Users\\BCD4~1\\AppData\\Local\\Temp\\tmprxgk6up2\n",
      "2020-10-18 23:07:14,142 loading file C:\\Users\\Эрнеста\\.flair\\models\\pos-multi-v0.1.pt\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "m = Mystem()\n",
    "\n",
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "\n",
    "    Doc\n",
    ")\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "tagger = SequenceTagger.load('pos-multi')\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы довольно скоро столкнемся с тем, насколько разные теги испоьзуются разными, эм, теггерами. Давайте профиксим это сразу? Существительные везде одним тегом, глаголы тоже, а прилагательные и наречия пихнем в одну категорию А - так люди делают, честно. Все равно же свойство.\n",
    "Так что у нас будут A, N, V, CONJ, PREP, PART, PRON\n",
    "Дальше лезть мы не будем. Давайте просто функцию для этого соорудим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tags(first_tag):\n",
    "    if first_tag in {'ADV', 'ADJ', 'A', 'ADJS', 'ADJF', 'COMP', 'PRTF', 'PRTS', 'ADVB', 'NUM', 'NUMR', 'ANUM', 'PRED', 'ADVPRO', 'APRO', 'COM'}:\n",
    "        last_tag = 'A'\n",
    "    elif first_tag in {'NOUN', 'S', 'PROPN', 'INTJ'}:\n",
    "        last_tag = 'N'    \n",
    "    elif first_tag in {'VERB', 'V', 'INFN', 'GRND', 'AUX'}:\n",
    "        last_tag = 'V'    \n",
    "    elif first_tag in {'SCONJ', 'CCONJ', 'CONJ'}:\n",
    "        last_tag = 'CONJ'    \n",
    "    elif first_tag in {'ADP', 'PR', 'PREP'}:\n",
    "        last_tag = 'PREP'    \n",
    "    elif first_tag in {'PART', 'PRCL'}:\n",
    "        last_tag = 'PART'\n",
    "    elif first_tag in {'DET', 'PRON', 'NPRO', 'SPRO'}:\n",
    "        last_tag = 'PRON'  \n",
    "    else:\n",
    "        last_tag = first_tag\n",
    "        \n",
    "        \n",
    "    return last_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Приходящие и уходящие из магазина покупатели охрану бесили неимоверно. Несмотря на то, что работали те спустя рукава и не смотря вокруг, у них было статус-кво и острое чувство справедливости! И дубинки. Их де-юре бессменное владение территорией де-факто ограничивалось кассой да пятачком у автоматиков. Тем не менее, им было где разгуляться, особенно утром – в гостиной отеля, хотя бы, хоть она и выходила за рамки магазинчика у ограды. Охранники туда выбирались, хоть ты тресни – кто им запретит? Разве что УК РФ, и то не факт. Книжицей законности им в наглые лица еще никто не натыкал, хотя горничные типа Ниночки и порывались. Сильно смелых в штате не нашлось ни тем утром, ни любым другим.\n"
     ]
    }
   ],
   "source": [
    "TEXT1 = '''Приходящие и уходящие из магазина покупатели охрану бесили неимоверно. Несмотря на то, что работали те спустя рукава и не смотря вокруг, у них было статус-кво и острое чувство справедливости! И дубинки. Их де-юре бессменное владение территорией де-факто ограничивалось кассой да пятачком у автоматиков. Тем не менее, им было где разгуляться, особенно утром – в гостиной отеля, хотя бы, хоть она и выходила за рамки магазинчика у ограды. Охранники туда выбирались, хоть ты тресни – кто им запретит? Разве что УК РФ, и то не факт. Книжицей законности им в наглые лица еще никто не натыкал, хотя горничные типа Ниночки и порывались. Сильно смелых в штате не нашлось ни тем утром, ни любым другим.'''\n",
    "print(TEXT1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT = [{'слово': 'приходящие', 'разбор': 'V'},\n",
    " {'слово': 'и', 'разбор': 'CONJ'},\n",
    " {'слово': 'уходящие', 'разбор': 'V'},\n",
    " {'слово': 'из', 'разбор': 'PREP'},\n",
    " {'слово': 'магазина', 'разбор': 'N'},\n",
    " {'слово': 'покупатели', 'разбор': 'N'},\n",
    " {'слово': 'охрану', 'разбор': 'N'},\n",
    " {'слово': 'бесили', 'разбор': 'V'}, #глянем, как отнесется к просторечным\n",
    " {'слово': 'неимоверно', 'разбор': 'A'},#или просто к редким\n",
    " {'слово': 'несмотря', 'разбор': 'PREP'},#ну это классика\n",
    " {'слово': 'на', 'разбор': 'PREP'},\n",
    " {'слово': 'то', 'разбор': 'PRON'},\n",
    " {'слово': 'что', 'разбор': 'CONJ'},\n",
    " {'слово': 'работали', 'разбор': 'V'},\n",
    " {'слово': 'те', 'разбор': 'PRON'},\n",
    " {'слово': 'спустя', 'разбор': 'V'},#а вдруг примет за предлог?\n",
    " {'слово': 'рукава', 'разбор': 'N'},\n",
    " {'слово': 'и', 'разбор': 'CONJ'},\n",
    " {'слово': 'не', 'разбор': 'PART'},\n",
    " {'слово': 'смотря', 'разбор': 'V'},\n",
    " {'слово': 'вокруг', 'разбор': 'A'},\n",
    " {'слово': 'у', 'разбор': 'PREP'},\n",
    " {'слово': 'них', 'разбор': 'PRON'},\n",
    " {'слово': 'было', 'разбор': 'V'},\n",
    " {'слово': 'статус-кво', 'разбор': 'N'},#дефис!\n",
    " {'слово': 'и', 'разбор': 'CONJ'},\n",
    " {'слово': 'острое', 'разбор': 'A'},\n",
    " {'слово': 'чувство', 'разбор': 'N'},\n",
    " {'слово': 'справедливости', 'разбор': 'N'},\n",
    " {'слово': 'и', 'разбор': 'CONJ'},\n",
    " {'слово': 'дубинки', 'разбор': 'N'},\n",
    " {'слово': 'их', 'разбор': 'PRON'},\n",
    " {'слово': 'де-юре', 'разбор': 'A'},#опять же, дефис и нечастое слово\n",
    " {'слово': 'бессменное', 'разбор': 'A'},\n",
    " {'слово': 'владение', 'разбор': 'N'},\n",
    " {'слово': 'территорией', 'разбор': 'N'},\n",
    " {'слово': 'де-факто', 'разбор': 'A'},#почаще, но да, дефис\n",
    " {'слово': 'ограничивалось', 'разбор': 'V'},\n",
    " {'слово': 'кассой', 'разбор': 'N'},\n",
    " {'слово': 'да', 'разбор': 'CONJ'},#а вдруг не засчитает за союз?\n",
    " {'слово': 'пятачком', 'разбор': 'N'},\n",
    " {'слово': 'у', 'разбор': 'PREP'},\n",
    " {'слово': 'автоматиков', 'разбор': 'N'},#редкий диминутив\n",
    " {'слово': 'тем', 'разбор': 'PRON'},\n",
    " {'слово': 'не', 'разбор': 'PART'},\n",
    " {'слово': 'менее', 'разбор': 'A'},\n",
    " {'слово': 'им', 'разбор': 'PRON'},\n",
    " {'слово': 'было', 'разбор': 'V'},\n",
    " {'слово': 'где', 'разбор': 'A'},\n",
    " {'слово': 'разгуляться', 'разбор': 'V'},\n",
    " {'слово': 'особенно', 'разбор': 'A'},\n",
    " {'слово': 'утром', 'разбор': 'A'},#а вот тут у нас утро наречное\n",
    " {'слово': 'в', 'разбор': 'PREP'},\n",
    " {'слово': 'гостиной', 'разбор': 'N'},#прилагательное али нет?\n",
    " {'слово': 'отеля', 'разбор': 'N'},\n",
    " {'слово': 'хотя', 'разбор': 'PART'},\n",
    " {'слово': 'бы', 'разбор': 'PART'},\n",
    " {'слово': 'хоть', 'разбор': 'PART'},\n",
    " {'слово': 'она', 'разбор': 'PRON'},\n",
    " {'слово': 'и', 'разбор': 'CONJ'},\n",
    " {'слово': 'выходила', 'разбор': 'V'},\n",
    " {'слово': 'за', 'разбор': 'PREP'},\n",
    " {'слово': 'пределы', 'разбор': 'N'},\n",
    " {'слово': 'магазинчика', 'разбор': 'N'},\n",
    " {'слово': 'у', 'разбор': 'PREP'},\n",
    " {'слово': 'ограды', 'разбор': 'N'},\n",
    " {'слово': 'охранники', 'разбор': 'N'},\n",
    " {'слово': 'туда', 'разбор': 'A'},\n",
    " {'слово': 'выбирались', 'разбор': 'V'},\n",
    " {'слово': 'хоть', 'разбор': 'PART'},\n",
    " {'слово': 'ты', 'разбор': 'PRON'},\n",
    " {'слово': 'тресни', 'разбор': 'V'},\n",
    " {'слово': 'кто', 'разбор': 'A'},\n",
    " {'слово': 'им', 'разбор': 'PRON'},\n",
    " {'слово': 'запретит', 'разбор': 'V'},\n",
    " {'слово': 'разве', 'разбор': 'PART'},\n",
    " {'слово': 'что', 'разбор': 'PART'},\n",
    " {'слово': 'ук', 'разбор': 'N'},#аббревиатуры!\n",
    " {'слово': 'рф', 'разбор': 'N'},#больше!\n",
    " {'слово': 'и', 'разбор': 'CONJ'},\n",
    " {'слово': 'то', 'разбор': 'PRON'},\n",
    " {'слово': 'не', 'разбор': 'PART'},\n",
    " {'слово': 'факт', 'разбор': 'N'},\n",
    " {'слово': 'книжицей', 'разбор': 'N'}, #больше низкочастотных слов!\n",
    " {'слово': 'законности', 'разбор': 'N'},\n",
    " {'слово': 'им', 'разбор': 'PRON'},\n",
    " {'слово': 'в', 'разбор': 'PREP'},\n",
    " {'слово': 'наглые', 'разбор': 'A'},\n",
    " {'слово': 'лица', 'разбор': 'N'},\n",
    " {'слово': 'еще', 'разбор': 'PART'},\n",
    " {'слово': 'никто', 'разбор': 'A'},\n",
    " {'слово': 'не', 'разбор': 'PART'},\n",
    " {'слово': 'натыкал', 'разбор': 'V'},\n",
    " {'слово': 'хотя', 'разбор': 'PART'},\n",
    " {'слово': 'горничные', 'разбор': 'N'},\n",
    " {'слово': 'типа', 'разбор': 'A'},#а вдруг примет за существительное?\n",
    " {'слово': 'ниночки', 'разбор': 'N'},#имя собственное, обязательно\n",
    " {'слово': 'и', 'разбор': 'CONJ'},\n",
    " {'слово': 'порывались', 'разбор': 'V'},\n",
    " {'слово': 'сильно', 'разбор': 'A'},\n",
    " {'слово': 'смелых', 'разбор': 'A'},\n",
    " {'слово': 'в', 'разбор': 'PREP'},\n",
    " {'слово': 'штате', 'разбор': 'N'},\n",
    " {'слово': 'не', 'разбор': 'PART'},\n",
    " {'слово': 'нашлось', 'разбор': 'V'},\n",
    " {'слово': 'ни', 'разбор': 'PART'},\n",
    " {'слово': 'тем', 'разбор': 'PRON'},\n",
    " {'слово': 'утром', 'разбор': 'A'},\n",
    " {'слово': 'ни', 'разбор': 'PART'},\n",
    " {'слово': 'любым', 'разбор': 'A'},\n",
    " {'слово': 'другим', 'разбор': 'A'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natasha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одной ячейкой подгрузим Наташе текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = Segmenter()\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "\n",
    "doc = Doc(TEXT1)\n",
    "doc.segment(segmenter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно размечать и запихивать в словарик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.tag_morph(morph_tagger)\n",
    "natasha_result = []\n",
    "poses = []\n",
    "for sent in doc.sents:\n",
    "    for mtoken in sent.morph.tokens:\n",
    "        t_dict = {}\n",
    "        t_dict['слово'] = mtoken.text.lower()\n",
    "        t_dict['разбор'] = convert_tags(mtoken.pos)\n",
    "        if not t_dict['разбор'] == 'PUNCT':\n",
    "            natasha_result.append(t_dict)\n",
    "            poses.append(t_dict['разбор'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И что там у Наташи?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'слово': 'приходящие', 'разбор': 'V'},\n",
       " {'слово': 'и', 'разбор': 'CONJ'},\n",
       " {'слово': 'уходящие', 'разбор': 'V'},\n",
       " {'слово': 'из', 'разбор': 'PREP'},\n",
       " {'слово': 'магазина', 'разбор': 'N'},\n",
       " {'слово': 'покупатели', 'разбор': 'N'},\n",
       " {'слово': 'охрану', 'разбор': 'N'},\n",
       " {'слово': 'бесили', 'разбор': 'V'},\n",
       " {'слово': 'неимоверно', 'разбор': 'A'},\n",
       " {'слово': 'несмотря', 'разбор': 'A'}]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "natasha_result[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pymorphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokens = word_tokenize(TEXT1)\n",
    "pymorphy_result = []\n",
    "for number, token in enumerate(tokens):\n",
    "    words = morph.parse(token)\n",
    "    form = words[0]\n",
    "    this_word = {}\n",
    "    this_word['слово'] = form.word\n",
    "    this_word['разбор'] = convert_tags(form.tag.POS)\n",
    "    if this_word['разбор'] != None:\n",
    "        pymorphy_result.append(this_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Он такой простой, радость-то какая. И что у него там?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'слово': 'приходящие', 'разбор': 'A'},\n",
       " {'слово': 'и', 'разбор': 'CONJ'},\n",
       " {'слово': 'уходящие', 'разбор': 'A'},\n",
       " {'слово': 'из', 'разбор': 'PREP'},\n",
       " {'слово': 'магазина', 'разбор': 'N'},\n",
       " {'слово': 'покупатели', 'разбор': 'N'},\n",
       " {'слово': 'охрану', 'разбор': 'N'},\n",
       " {'слово': 'бесили', 'разбор': 'V'},\n",
       " {'слово': 'неимоверно', 'разбор': 'A'},\n",
       " {'слово': 'несмотря', 'разбор': 'PREP'}]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pymorphy_result[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem_result = []\n",
    "full_stem = m.analyze(TEXT1)\n",
    "for word in full_stem:\n",
    "    if word.get('analysis') != None:\n",
    "        mystem_dict = {}\n",
    "        mystem_dict['слово'] = word['text'].lower()\n",
    "        mystem_dict['разбор'] = convert_tags(word['analysis'][0]['gr'].split('=')[0].split(',')[0])\n",
    "        mystem_result.append(mystem_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спросим у стема, как его дела:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'слово': 'приходящие', 'разбор': 'V'},\n",
       " {'слово': 'и', 'разбор': 'CONJ'},\n",
       " {'слово': 'уходящие', 'разбор': 'V'},\n",
       " {'слово': 'из', 'разбор': 'PREP'},\n",
       " {'слово': 'магазина', 'разбор': 'N'},\n",
       " {'слово': 'покупатели', 'разбор': 'N'},\n",
       " {'слово': 'охрану', 'разбор': 'N'},\n",
       " {'слово': 'бесили', 'разбор': 'V'},\n",
       " {'слово': 'неимоверно', 'разбор': 'A'},\n",
       " {'слово': 'несмотря', 'разбор': 'A'}]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_result[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Момент истины!\n",
    "Для начала, проверим, что все теггеры распарсили и заметили все слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if len(natasha_result)==len(mystem_result) and len(pymorphy_result)==len(natasha_result):\n",
    "    print('True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Порядок, их мнения сошлись. Организуем функцию для оценки акк:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_acc(any_result, RESULT):\n",
    "    detected_result = []\n",
    "    real_result = []\n",
    "    errors = []\n",
    "    for i, word in enumerate(any_result):\n",
    "        if word == RESULT[i]:\n",
    "            detected_result.append('pos')\n",
    "        else:\n",
    "            detected_result.append('neg')\n",
    "            errors.append([word, RESULT[i]])\n",
    "        real_result.append('pos')\n",
    "        \n",
    "    acc = accuracy_score(detected_result, real_result)\n",
    "    return acc, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\\*барабанная дробь**\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Natasha is: 0.8288288288288288 ;\n",
      " as mistakes, it had:  [[{'слово': 'несмотря', 'разбор': 'A'}, {'слово': 'несмотря', 'разбор': 'PREP'}], [{'слово': 'спустя', 'разбор': 'PREP'}, {'слово': 'спустя', 'разбор': 'V'}], [{'слово': 'бессменное', 'разбор': 'V'}, {'слово': 'бессменное', 'разбор': 'A'}], [{'слово': 'утром', 'разбор': 'N'}, {'слово': 'утром', 'разбор': 'A'}], [{'слово': 'хоть', 'разбор': 'CONJ'}, {'слово': 'хоть', 'разбор': 'PART'}], [{'слово': 'и', 'разбор': 'PART'}, {'слово': 'и', 'разбор': 'CONJ'}], [{'слово': 'рамки', 'разбор': 'N'}, {'слово': 'пределы', 'разбор': 'N'}], [{'слово': 'хоть', 'разбор': 'CONJ'}, {'слово': 'хоть', 'разбор': 'PART'}], [{'слово': 'кто', 'разбор': 'PRON'}, {'слово': 'кто', 'разбор': 'A'}], [{'слово': 'что', 'разбор': 'CONJ'}, {'слово': 'что', 'разбор': 'PART'}], [{'слово': 'еще', 'разбор': 'A'}, {'слово': 'еще', 'разбор': 'PART'}], [{'слово': 'никто', 'разбор': 'PRON'}, {'слово': 'никто', 'разбор': 'A'}], [{'слово': 'хотя', 'разбор': 'CONJ'}, {'слово': 'хотя', 'разбор': 'PART'}], [{'слово': 'типа', 'разбор': 'PREP'}, {'слово': 'типа', 'разбор': 'A'}], [{'слово': 'порывались', 'разбор': 'N'}, {'слово': 'порывались', 'разбор': 'V'}], [{'слово': 'ни', 'разбор': 'CONJ'}, {'слово': 'ни', 'разбор': 'PART'}], [{'слово': 'утром', 'разбор': 'N'}, {'слово': 'утром', 'разбор': 'A'}], [{'слово': 'ни', 'разбор': 'CONJ'}, {'слово': 'ни', 'разбор': 'PART'}], [{'слово': 'любым', 'разбор': 'PRON'}, {'слово': 'любым', 'разбор': 'A'}]]\n",
      "\n",
      " Accuracy of Mystem is: 0.8648648648648649 ;\n",
      " as mistakes, it had:  [[{'слово': 'несмотря', 'разбор': 'A'}, {'слово': 'несмотря', 'разбор': 'PREP'}], [{'слово': 'те', 'разбор': 'A'}, {'слово': 'те', 'разбор': 'PRON'}], [{'слово': 'спустя', 'разбор': 'PREP'}, {'слово': 'спустя', 'разбор': 'V'}], [{'слово': 'утром', 'разбор': 'N'}, {'слово': 'утром', 'разбор': 'A'}], [{'слово': 'рамки', 'разбор': 'N'}, {'слово': 'пределы', 'разбор': 'N'}], [{'слово': 'кто', 'разбор': 'PRON'}, {'слово': 'кто', 'разбор': 'A'}], [{'слово': 'что', 'разбор': 'CONJ'}, {'слово': 'что', 'разбор': 'PART'}], [{'слово': 'еще', 'разбор': 'A'}, {'слово': 'еще', 'разбор': 'PART'}], [{'слово': 'никто', 'разбор': 'PRON'}, {'слово': 'никто', 'разбор': 'A'}], [{'слово': 'хотя', 'разбор': 'CONJ'}, {'слово': 'хотя', 'разбор': 'PART'}], [{'слово': 'типа', 'разбор': 'N'}, {'слово': 'типа', 'разбор': 'A'}], [{'слово': 'ни', 'разбор': 'CONJ'}, {'слово': 'ни', 'разбор': 'PART'}], [{'слово': 'тем', 'разбор': 'A'}, {'слово': 'тем', 'разбор': 'PRON'}], [{'слово': 'утром', 'разбор': 'N'}, {'слово': 'утром', 'разбор': 'A'}], [{'слово': 'ни', 'разбор': 'CONJ'}, {'слово': 'ни', 'разбор': 'PART'}]]\n",
      "\n",
      " Accuracy of Pymorphy is: 0.7837837837837838 ;\n",
      " as mistakes, it had:  [[{'слово': 'приходящие', 'разбор': 'A'}, {'слово': 'приходящие', 'разбор': 'V'}], [{'слово': 'уходящие', 'разбор': 'A'}, {'слово': 'уходящие', 'разбор': 'V'}], [{'слово': 'то', 'разбор': 'CONJ'}, {'слово': 'то', 'разбор': 'PRON'}], [{'слово': 'те', 'разбор': 'A'}, {'слово': 'те', 'разбор': 'PRON'}], [{'слово': 'спустя', 'разбор': 'PREP'}, {'слово': 'спустя', 'разбор': 'V'}], [{'слово': 'да', 'разбор': 'PART'}, {'слово': 'да', 'разбор': 'CONJ'}], [{'слово': 'тем', 'разбор': 'CONJ'}, {'слово': 'тем', 'разбор': 'PRON'}], [{'слово': 'им', 'разбор': 'N'}, {'слово': 'им', 'разбор': 'PRON'}], [{'слово': 'гостиной', 'разбор': 'A'}, {'слово': 'гостиной', 'разбор': 'N'}], [{'слово': 'хотя', 'разбор': 'CONJ'}, {'слово': 'хотя', 'разбор': 'PART'}], [{'слово': 'хоть', 'разбор': 'CONJ'}, {'слово': 'хоть', 'разбор': 'PART'}], [{'слово': 'рамки', 'разбор': 'N'}, {'слово': 'пределы', 'разбор': 'N'}], [{'слово': 'хоть', 'разбор': 'CONJ'}, {'слово': 'хоть', 'разбор': 'PART'}], [{'слово': 'кто', 'разбор': 'PRON'}, {'слово': 'кто', 'разбор': 'A'}], [{'слово': 'им', 'разбор': 'N'}, {'слово': 'им', 'разбор': 'PRON'}], [{'слово': 'что', 'разбор': 'CONJ'}, {'слово': 'что', 'разбор': 'PART'}], [{'слово': 'то', 'разбор': 'CONJ'}, {'слово': 'то', 'разбор': 'PRON'}], [{'слово': 'им', 'разбор': 'N'}, {'слово': 'им', 'разбор': 'PRON'}], [{'слово': 'ещё', 'разбор': 'PART'}, {'слово': 'еще', 'разбор': 'PART'}], [{'слово': 'никто', 'разбор': 'PRON'}, {'слово': 'никто', 'разбор': 'A'}], [{'слово': 'хотя', 'разбор': 'CONJ'}, {'слово': 'хотя', 'разбор': 'PART'}], [{'слово': 'горничные', 'разбор': 'A'}, {'слово': 'горничные', 'разбор': 'N'}], [{'слово': 'типа', 'разбор': 'N'}, {'слово': 'типа', 'разбор': 'A'}], [{'слово': 'тем', 'разбор': 'CONJ'}, {'слово': 'тем', 'разбор': 'PRON'}]]\n"
     ]
    }
   ],
   "source": [
    "acc_tash, err_tash = detect_acc(natasha_result, RESULT)\n",
    "print('Accuracy of Natasha is:', acc_tash, ';\\n as mistakes, it had: ', err_tash)\n",
    "acc_stem, err_stem = detect_acc(mystem_result, RESULT)\n",
    "print('\\n Accuracy of Mystem is:', acc_stem, ';\\n as mistakes, it had: ', err_stem)\n",
    "acc_morph, err_morph = detect_acc(pymorphy_result, RESULT)\n",
    "print('\\n Accuracy of Pymorphy is:', acc_morph, ';\\n as mistakes, it had: ', err_morph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Майстем такой...хороший?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Английский язык"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To put it mildly, all of that was weird. They were weirdos! All these insane shenanigans were frying my mind. No way this was happening. God damn. Oh, these people, they tried to help! They were my main source of inspiration, little softies. But the odds of me getting out were slim. I had to part from here, I really did. But what would that cost me?  At what cost would I manage? I put my sharpie away and stayed put. The light was light and soft. I was starting to doubt my silly doubts beyond all rational thought. There was no return, no safehouse. The end was closing in.\n"
     ]
    }
   ],
   "source": [
    "TEXT2 = '''To put it mildly, all of that was weird. They were weirdos! All these insane shenanigans were frying my mind. No way this was happening. God damn. Oh, these people, they tried to help! They were my main source of inspiration, little softies. But the odds of me getting out were slim. I had to part from here, I really did. But what would that cost me?  At what cost would I manage? I put my sharpie away and stayed put. The light was light and soft. I was starting to doubt my silly doubts beyond all rational thought. There was no return, no safehouse. The end was closing in.'''\n",
    "print(TEXT2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT2 = [{'слово': 'To', 'разбор': 'PART'},\n",
    " {'слово': 'put', 'разбор': 'V'},\n",
    " {'слово': 'it', 'разбор': 'PRON'},\n",
    " {'слово': 'mildly', 'разбор': 'A'},\n",
    " {'слово': 'all', 'разбор': 'DET'},\n",
    " {'слово': 'of', 'разбор': 'PREP'},\n",
    " {'слово': 'that', 'разбор': 'DET'},\n",
    " {'слово': 'was', 'разбор': 'V'},\n",
    " {'слово': 'weird', 'разбор': 'A'},\n",
    " {'слово': 'They', 'разбор': 'PRON'},\n",
    " {'слово': 'were', 'разбор': 'V'},\n",
    " {'слово': \"weirdos\", 'разбор': 'N'},#rare word! derived\n",
    " {'слово': 'All', 'разбор': 'DET'},\n",
    " {'слово': 'these', 'разбор': 'DET'},\n",
    " {'слово': 'insane', 'разбор': 'A'},\n",
    " {'слово': 'shenanigans', 'разбор': 'N'},\n",
    " {'слово': 'were', 'разбор': 'V'},\n",
    " {'слово': 'frying', 'разбор': 'V'},\n",
    " {'слово': 'my', 'разбор': 'PRON'},\n",
    " {'слово': 'mind', 'разбор': 'N'},\n",
    " {'слово': 'No', 'разбор': 'DET'},\n",
    " {'слово': 'way', 'разбор': 'N'},\n",
    " {'слово': 'this', 'разбор': 'DET'},\n",
    " {'слово': 'was', 'разбор': 'V'},\n",
    " {'слово': 'happening', 'разбор': 'V'},\n",
    " {'слово': 'God', 'разбор': 'N'},\n",
    " {'слово': 'damn', 'разбор': 'V'},\n",
    " {'слово': 'Oh', 'разбор': 'INTJ'},#always good to see an INTJ\n",
    " {'слово': 'these', 'разбор': 'DET'},\n",
    " {'слово': 'people', 'разбор': 'N'},\n",
    " {'слово': 'they', 'разбор': 'PRON'},\n",
    " {'слово': 'tried', 'разбор': 'V'},\n",
    " {'слово': 'to', 'разбор': 'PART'},\n",
    " {'слово': 'help', 'разбор': 'V'},\n",
    " {'слово': 'They', 'разбор': 'PRON'},\n",
    " {'слово': 'were', 'разбор': 'V'},\n",
    " {'слово': 'my', 'разбор': 'PRON'},\n",
    " {'слово': 'main', 'разбор': 'A'},\n",
    " {'слово': 'source', 'разбор': 'N'},\n",
    " {'слово': 'of', 'разбор': 'PREP'},\n",
    " {'слово': 'inspiration', 'разбор': 'N'},\n",
    " {'слово': 'little', 'разбор': 'A'},\n",
    " {'слово': 'softies', 'разбор': 'N'},#rare word...kinda\n",
    " {'слово': 'But', 'разбор': 'CONJ'},\n",
    " {'слово': 'the', 'разбор': 'DET'},\n",
    " {'слово': 'odds', 'разбор': 'N'},\n",
    " {'слово': 'of', 'разбор': 'PREP'},\n",
    " {'слово': 'me', 'разбор': 'PRON'},\n",
    " {'слово': 'getting', 'разбор': 'V'},\n",
    " {'слово': 'out', 'разбор': 'PREP'},\n",
    " {'слово': 'were', 'разбор': 'V'},\n",
    " {'слово': 'slim', 'разбор': 'A'},\n",
    " {'слово': 'I', 'разбор': 'PRON'},\n",
    " {'слово': 'had', 'разбор': 'V'},\n",
    " {'слово': 'to', 'разбор': 'PART'},\n",
    " {'слово': 'part', 'разбор': 'N'},#\n",
    " {'слово': 'from', 'разбор': 'PREP'},\n",
    " {'слово': 'here', 'разбор': 'A'},\n",
    " {'слово': 'I', 'разбор': 'PRON'},\n",
    " {'слово': 'really', 'разбор': 'A'},\n",
    " {'слово': 'did', 'разбор': 'V'},\n",
    " {'слово': 'But', 'разбор': 'CONJ'},\n",
    " {'слово': 'what', 'разбор': 'PRON'},\n",
    " {'слово': 'would', 'разбор': 'V'},\n",
    " {'слово': 'that', 'разбор': 'DET'},\n",
    " {'слово': 'cost', 'разбор': 'V'},#noun? verb? who are we?\n",
    " {'слово': 'me', 'разбор': 'PRON'},\n",
    " {'слово': 'At', 'разбор': 'PREP'},\n",
    " {'слово': 'what', 'разбор': 'PRON'},\n",
    " {'слово': 'cost', 'разбор': 'N'},#yeah, once again\n",
    " {'слово': 'would', 'разбор': 'V'},\n",
    " {'слово': 'I', 'разбор': 'PRON'},\n",
    " {'слово': 'manage', 'разбор': 'V'},\n",
    " {'слово': 'I', 'разбор': 'PRON'},\n",
    " {'слово': 'put', 'разбор': 'V'},\n",
    " {'слово': 'my', 'разбор': 'PRON'},\n",
    " {'слово': 'sharpie', 'разбор': 'N'},#rare derivative\n",
    " {'слово': 'away', 'разбор': 'PREP'},\n",
    " {'слово': 'and', 'разбор': 'CONJ'},\n",
    " {'слово': 'stayed', 'разбор': 'V'},\n",
    " {'слово': 'put', 'разбор': 'V'},\n",
    " {'слово': 'The', 'разбор': 'DET'},\n",
    " {'слово': 'light', 'разбор': 'N'},\n",
    " {'слово': 'was', 'разбор': 'V'},\n",
    " {'слово': 'light', 'разбор': 'A'},#yes, i'm being ridiculous\n",
    " {'слово': 'and', 'разбор': 'CONJ'},\n",
    " {'слово': 'soft', 'разбор': 'A'},\n",
    " {'слово': 'I', 'разбор': 'PRON'},\n",
    " {'слово': 'was', 'разбор': 'V'},\n",
    " {'слово': 'starting', 'разбор': 'V'},\n",
    " {'слово': 'to', 'разбор': 'PART'},\n",
    " {'слово': 'doubt', 'разбор': 'V'},\n",
    " {'слово': 'my', 'разбор': 'PRON'},\n",
    " {'слово': 'silly', 'разбор': 'A'},\n",
    " {'слово': 'doubts', 'разбор': 'N'},#uh-huh, now its a noun\n",
    " {'слово': 'beyond', 'разбор': 'PREP'},\n",
    " {'слово': 'all', 'разбор': 'DET'},\n",
    " {'слово': 'rational', 'разбор': 'A'},\n",
    " {'слово': 'thought', 'разбор': 'N'},\n",
    " {'слово': 'There', 'разбор': 'DET'},\n",
    " {'слово': 'was', 'разбор': 'V'},\n",
    " {'слово': 'no', 'разбор': 'DET'},\n",
    " {'слово': 'return', 'разбор': 'N'},#is it a noun? only we know!\n",
    " {'слово': 'no', 'разбор': 'DET'},\n",
    " {'слово': 'safehouse', 'разбор': 'N'},#pretty rare, right?\n",
    " {'слово': 'The', 'разбор': 'DET'},\n",
    " {'слово': 'end', 'разбор': 'N'},#who knows? maybe it's easy to see as a verb\n",
    " {'слово': 'was', 'разбор': 'V'},\n",
    " {'слово': 'closing', 'разбор': 'V'},\n",
    " {'слово': 'in', 'разбор': 'PREP'},]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут появляется еще артикль, сокращения и прочие приятные штуки - изменим немного функцию для унификации тегов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_eng_tags(first_tag):\n",
    "    if first_tag in {'ADJ', 'ADV', 'RB', 'RBR', 'RBS', 'JJ', 'JJR', 'JJS', }:\n",
    "        last_tag = 'A'\n",
    "    elif first_tag in {'PROPN', 'NOUN', 'NN', 'NNS', 'NNP', 'NNPS'}:\n",
    "        last_tag = 'N'    \n",
    "    elif first_tag in  {'VERB', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'MD', 'AUX'}:\n",
    "        last_tag = 'V'    \n",
    "    elif first_tag in {'SCONJ', 'CCONJ', 'CONJ', 'CC'}:\n",
    "        last_tag = 'CONJ'    \n",
    "    elif first_tag in {'ADP', 'TO', 'IN'}:\n",
    "        last_tag = 'PREP'    \n",
    "    elif first_tag in {'PART', 'POS', 'RP'}:\n",
    "        last_tag = 'PART'\n",
    "    elif first_tag in {'PRON', 'WDT', 'WP', 'WP$', 'WRB', 'PRP', 'PRP$', 'EX'}:\n",
    "        last_tag = 'PRON'  \n",
    "    elif first_tag in {'DT', 'DET', 'PDT'}:\n",
    "        last_tag = 'DET'  \n",
    "    elif first_tag in {'NUM', 'CD'}:\n",
    "        last_tag = 'NUM'  \n",
    "    elif first_tag in {'INTJ', 'UH'}:\n",
    "        last_tag = 'INTJ'  \n",
    "    else:\n",
    "        last_tag = 'PUNCT'\n",
    "        \n",
    "        \n",
    "    return last_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(TEXT2)\n",
    "spacy_result = []\n",
    "for sent in doc.sents:\n",
    "    for t in sent:\n",
    "        word = {}\n",
    "        word['слово'] = t.text\n",
    "        word['разбор'] = convert_eng_tags(t.pos_)\n",
    "        if word['разбор'] != 'PUNCT':\n",
    "            spacy_result.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'слово': 'To', 'разбор': 'PART'},\n",
       " {'слово': 'put', 'разбор': 'V'},\n",
       " {'слово': 'it', 'разбор': 'PRON'},\n",
       " {'слово': 'mildly', 'разбор': 'A'},\n",
       " {'слово': 'all', 'разбор': 'DET'},\n",
       " {'слово': 'of', 'разбор': 'PREP'},\n",
       " {'слово': 'that', 'разбор': 'DET'},\n",
       " {'слово': 'was', 'разбор': 'V'},\n",
       " {'слово': 'weird', 'разбор': 'A'},\n",
       " {'слово': 'They', 'разбор': 'PRON'}]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_result[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentence = Sentence(TEXT2)\n",
    "tagger.predict(sentence)\n",
    "\n",
    "f_result = sentence.to_tagged_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_result = []\n",
    "for word in f_result.split('> '):\n",
    "    word = word.split(' <')\n",
    "    new_word = {}\n",
    "    new_word['слово'] = word[0]\n",
    "    new_word['разбор'] = convert_eng_tags(word[1].strip('>'))\n",
    "    if new_word['разбор'] != 'PUNCT':\n",
    "        flair_result.append(new_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'слово': 'To', 'разбор': 'PART'},\n",
       " {'слово': 'put', 'разбор': 'V'},\n",
       " {'слово': 'it', 'разбор': 'PRON'},\n",
       " {'слово': 'mildly', 'разбор': 'A'},\n",
       " {'слово': 'all', 'разбор': 'DET'},\n",
       " {'слово': 'of', 'разбор': 'PREP'},\n",
       " {'слово': 'that', 'разбор': 'PRON'},\n",
       " {'слово': 'was', 'разбор': 'V'},\n",
       " {'слово': 'weird', 'разбор': 'A'},\n",
       " {'слово': 'They', 'разбор': 'PRON'}]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flair_result[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(TEXT2)\n",
    "nltk_result = []\n",
    "for word in nltk.pos_tag(tokens):\n",
    "    new_word = {}\n",
    "    new_word['слово'] = word[0]\n",
    "    new_word['разбор'] = convert_eng_tags(word[1])\n",
    "    if new_word['разбор'] != 'PUNCT':\n",
    "        nltk_result.append(new_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'слово': 'To', 'разбор': 'PREP'},\n",
       " {'слово': 'put', 'разбор': 'V'},\n",
       " {'слово': 'it', 'разбор': 'PRON'},\n",
       " {'слово': 'mildly', 'разбор': 'A'},\n",
       " {'слово': 'all', 'разбор': 'DET'},\n",
       " {'слово': 'of', 'разбор': 'PREP'},\n",
       " {'слово': 'that', 'разбор': 'DET'},\n",
       " {'слово': 'was', 'разбор': 'V'},\n",
       " {'слово': 'weird', 'разбор': 'A'},\n",
       " {'слово': 'They', 'разбор': 'PRON'}]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_result[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are! The moment of truth!\n",
    "Obviously, we start with checking the lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if len(spacy_result)==len(flair_result) and len(flair_result)==len(nltk_result):\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All clear! Let's do this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Spacy is: 0.9090909090909091 ;\n",
      " as mistakes, it had:  [[{'слово': 'my', 'разбор': 'DET'}, {'слово': 'my', 'разбор': 'PRON'}], [{'слово': 'damn', 'разбор': 'INTJ'}, {'слово': 'damn', 'разбор': 'V'}], [{'слово': 'my', 'разбор': 'DET'}, {'слово': 'my', 'разбор': 'PRON'}], [{'слово': 'out', 'разбор': 'A'}, {'слово': 'out', 'разбор': 'PREP'}], [{'слово': 'part', 'разбор': 'V'}, {'слово': 'part', 'разбор': 'N'}], [{'слово': 'what', 'разбор': 'DET'}, {'слово': 'what', 'разбор': 'PRON'}], [{'слово': 'my', 'разбор': 'DET'}, {'слово': 'my', 'разбор': 'PRON'}], [{'слово': 'away', 'разбор': 'A'}, {'слово': 'away', 'разбор': 'PREP'}], [{'слово': 'my', 'разбор': 'DET'}, {'слово': 'my', 'разбор': 'PRON'}], [{'слово': 'There', 'разбор': 'PRON'}, {'слово': 'There', 'разбор': 'DET'}]]\n",
      "\n",
      " Accuracy of Flair is: 0.9 ;\n",
      " as mistakes, it had:  [[{'слово': 'that', 'разбор': 'PRON'}, {'слово': 'that', 'разбор': 'DET'}], [{'слово': 'this', 'разбор': 'PRON'}, {'слово': 'this', 'разбор': 'DET'}], [{'слово': 'damn', 'разбор': 'A'}, {'слово': 'damn', 'разбор': 'V'}], [{'слово': 'out', 'разбор': 'A'}, {'слово': 'out', 'разбор': 'PREP'}], [{'слово': 'part', 'разбор': 'V'}, {'слово': 'part', 'разбор': 'N'}], [{'слово': 'that', 'разбор': 'PRON'}, {'слово': 'that', 'разбор': 'DET'}], [{'слово': 'what', 'разбор': 'DET'}, {'слово': 'what', 'разбор': 'PRON'}], [{'слово': 'away', 'разбор': 'A'}, {'слово': 'away', 'разбор': 'PREP'}], [{'слово': 'put', 'разбор': 'A'}, {'слово': 'put', 'разбор': 'V'}], [{'слово': 'There', 'разбор': 'PRON'}, {'слово': 'There', 'разбор': 'DET'}], [{'слово': 'in', 'разбор': 'A'}, {'слово': 'in', 'разбор': 'PREP'}]]\n",
      "\n",
      " Accuracy of NLTK is: 0.9090909090909091 ;\n",
      " as mistakes, it had:  [[{'слово': 'To', 'разбор': 'PREP'}, {'слово': 'To', 'разбор': 'PART'}], [{'слово': 'weirdos', 'разбор': 'A'}, {'слово': 'weirdos', 'разбор': 'N'}], [{'слово': 'damn', 'разбор': 'N'}, {'слово': 'damn', 'разбор': 'V'}], [{'слово': 'to', 'разбор': 'PREP'}, {'слово': 'to', 'разбор': 'PART'}], [{'слово': 'out', 'разбор': 'PART'}, {'слово': 'out', 'разбор': 'PREP'}], [{'слово': 'to', 'разбор': 'PREP'}, {'слово': 'to', 'разбор': 'PART'}], [{'слово': 'away', 'разбор': 'A'}, {'слово': 'away', 'разбор': 'PREP'}], [{'слово': 'put', 'разбор': 'N'}, {'слово': 'put', 'разбор': 'V'}], [{'слово': 'to', 'разбор': 'PREP'}, {'слово': 'to', 'разбор': 'PART'}], [{'слово': 'There', 'разбор': 'PRON'}, {'слово': 'There', 'разбор': 'DET'}]]\n"
     ]
    }
   ],
   "source": [
    "acc_spacy, err_spacy = detect_acc(spacy_result, RESULT2)\n",
    "print('Accuracy of Spacy is:', acc_spacy, ';\\n as mistakes, it had: ', err_spacy)\n",
    "acc_flair, err_flair = detect_acc(flair_result, RESULT2)\n",
    "print('\\n Accuracy of Flair is:', acc_flair, ';\\n as mistakes, it had: ', err_flair)\n",
    "acc_nltk, err_nltk = detect_acc(nltk_result, RESULT2)\n",
    "print('\\n Accuracy of NLTK is:', acc_nltk, ';\\n as mistakes, it had: ', err_nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are so good!\n",
    "And i think i'm starting to doubt my own morphology."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
