{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6Ctpz7uq6nQ"
      },
      "source": [
        "# Генсим и остальные неприятности"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSaaJX3XrBAt"
      },
      "source": [
        "## Импорты и подготовка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZwU9jJWfDXz",
        "outputId": "42b399e0-1b03-4a81-e49c-6f3500a45b69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import nltk; nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "import pandas as pd\n",
        "\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtDnIO6yrImz"
      },
      "source": [
        "ознакомимся с нашим датасетом - загрузим его в панды, по красивой пандовской традиции всяких датасайентистов назовем датафреймом.\n",
        "\n",
        "что у нас в его верхушке?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwhwjM_8gDkC",
        "outputId": "8cc859b5-4800-43e7-a8af-ab998eee1b4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "df = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
        "print(df.target_names.unique())\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['rec.autos' 'comp.sys.mac.hardware' 'comp.graphics' 'sci.space'\n",
            " 'talk.politics.guns' 'sci.med' 'comp.sys.ibm.pc.hardware'\n",
            " 'comp.os.ms-windows.misc' 'rec.motorcycles' 'talk.religion.misc'\n",
            " 'misc.forsale' 'alt.atheism' 'sci.electronics' 'comp.windows.x'\n",
            " 'rec.sport.hockey' 'rec.sport.baseball' 'soc.religion.christian'\n",
            " 'talk.politics.mideast' 'talk.politics.misc' 'sci.crypt']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target</th>\n",
              "      <th>target_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
              "      <td>7</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
              "      <td>14</td>\n",
              "      <td>sci.space</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  ...           target_names\n",
              "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...  ...              rec.autos\n",
              "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...  ...  comp.sys.mac.hardware\n",
              "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...  ...  comp.sys.mac.hardware\n",
              "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...  ...          comp.graphics\n",
              "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...  ...              sci.space\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti5mWKT_wIUY"
      },
      "source": [
        "## Очистка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiV5DTxOr9UG"
      },
      "source": [
        "Почистим эти данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFdEZZ_PgaML",
        "outputId": "58379751-03e0-4f6c-c4ae-97d486781294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "data = df.content.values.tolist()\n",
        "\n",
        "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
        "\n",
        "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
        "\n",
        "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
        "\n",
        "pprint(data[:1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['From: (wheres my thing) Subject: WHAT car is this!? Nntp-Posting-Host: '\n",
            " 'rac3.wam.umd.edu Organization: University of Maryland, College Park Lines: '\n",
            " '15 I was wondering if anyone out there could enlighten me on this car I saw '\n",
            " 'the other day. It was a 2-door sports car, looked to be from the late 60s/ '\n",
            " 'early 70s. It was called a Bricklin. The doors were really small. In '\n",
            " 'addition, the front bumper was separate from the rest of the body. This is '\n",
            " 'all I know. If anyone can tellme a model name, engine specs, years of '\n",
            " 'production, where this car is made, history, or whatever info you have on '\n",
            " 'this funky looking car, please e-mail. Thanks, - IL ---- brought to you by '\n",
            " 'your neighborhood Lerxst ---- ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOZgSecUsd1-"
      },
      "source": [
        "парсим предложения до уровня слов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KXVcCMmgiKt",
        "outputId": "de6996d8-48a4-440f-b131-0b86b5077fe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data_words = list(sent_to_words(data))\n",
        "\n",
        "print(data_words[:1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['from', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp', 'posting', 'host', 'rac', 'wam', 'umd', 'edu', 'organization', 'university', 'of', 'maryland', 'college', 'park', 'lines', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front', 'bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuaJLwxkwO8I"
      },
      "source": [
        "## Генсим"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pk0UD3H_sxpx"
      },
      "source": [
        "Мы дошли до генсима! Пойдем попросим его скрафтить биграммы и триграммы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBNklOBEgmPm",
        "outputId": "edb49b84-08ef-4c52-94ce-642af8f2080f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
        "\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "\n",
        "print(trigram_mod[bigram_mod[data_words[0]]])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['from', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp_posting_host', 'rac_wam_umd_edu', 'organization', 'university', 'of', 'maryland_college_park', 'lines', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front_bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ18G-zMs3G8"
      },
      "source": [
        "Теперь создадим функции для обращения к генсиму"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rct1iU6lgsS5"
      },
      "source": [
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JxxM8i7gxR2",
        "outputId": "48d17ad3-9bdb-4a78-f573-2a29458b9668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "data_words_nostops = remove_stopwords(data_words)\n",
        "\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "print(data_lemmatized[:1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['where', 'thing', 'car', 'nntp_poste', 'host', 'park', 'line', 'wonder', 'could', 'enlighten', 'car', 'see', 'day', 'door', 'sport', 'car', 'look', 'late', 'early', 'call', 'bricklin', 'door', 'really', 'small', 'addition', 'separate', 'rest', 'body', 'know', 'tellme', 'model', 'name', 'engine', 'year', 'production', 'car', 'make', 'history', 'info', 'funky', 'look', 'car', 'mail', 'thank', 'bring', 'neighborhood', 'lerxst']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI3tQ24tt0eC"
      },
      "source": [
        "Мы готовим обучающий датасет!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOB2iaplhLhN",
        "outputId": "85665658-dc79-4f94-cb3f-f8fc8e5dafc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "\n",
        "texts = data_lemmatized\n",
        "\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "print(corpus[:1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 5), (6, 1), (7, 1), (8, 2), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGomEMRxt4gj"
      },
      "source": [
        "А теперь создаем функцию, которая найдет нам лучшие параметры"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va4T6Tb9hLlM"
      },
      "source": [
        "def choose_score(start, number, rate, corpus, id2word, data_lemmatized):\n",
        "    best_coh = 0\n",
        "    best_num = 0\n",
        "    best_top = ''\n",
        "    for i in range(start, number, rate):\n",
        "        print(i)\n",
        "        lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=i, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)\n",
        "\n",
        "        coherence_lda_model = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "        coherence_lda = coherence_lda_model.get_coherence()\n",
        "        if coherence_lda > best_coh:\n",
        "            best_coh = coherence_lda\n",
        "            best_num = i\n",
        "            best_model = lda_model\n",
        "            print(best_coh, best_num)\n",
        "\n",
        "    return (best_coh, best_num, best_model)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSwPQSGrhjCI",
        "outputId": "a2b6bf20-e327-4a97-962a-6932886c55a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "choose_score(5, 30, 5, corpus, id2word, data_lemmatized)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "0.4297369063851419 5\n",
            "10\n",
            "0.4973497938960755 10\n",
            "15\n",
            "20\n",
            "25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4973497938960755, 10, <gensim.models.ldamodel.LdaModel at 0x7fbf26ceac88>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8O3sXJxguGSJ"
      },
      "source": [
        "Сама функция для генсимовской модели!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydXtpz5Ch1PE"
      },
      "source": [
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=10, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)\n",
        "doc_lda = lda_model[corpus]\n",
        "t = lda_model.print_topics()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hvqiVpNh_kA",
        "outputId": "39a22c6d-02a4-49ea-96ef-8a2f03a60a7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "list(t)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.028*\"team\" + 0.027*\"year\" + 0.026*\"game\" + 0.020*\"play\" + 0.018*\"win\" + 0.014*\"player\" + 0.010*\"run\" + 0.010*\"last\" + 0.009*\"good\" + 0.009*\"hit\"'),\n",
              " (1,\n",
              "  '0.022*\"go\" + 0.015*\"time\" + 0.013*\"day\" + 0.012*\"come\" + 0.011*\"take\" + 0.011*\"back\" + 0.011*\"get\" + 0.009*\"say\" + 0.008*\"see\" + 0.008*\"first\"'),\n",
              " (2,\n",
              "  '0.014*\"space\" + 0.008*\"cost\" + 0.008*\"year\" + 0.007*\"high\" + 0.007*\"research\" + 0.007*\"low\" + 0.006*\"item\" + 0.006*\"also\" + 0.006*\"test\" + 0.005*\"large\"'),\n",
              " (3,\n",
              "  '0.033*\"car\" + 0.021*\"drive\" + 0.013*\"bike\" + 0.011*\"power\" + 0.011*\"wire\" + 0.011*\"slave\" + 0.010*\"reality\" + 0.009*\"speed\" + 0.009*\"engine\" + 0.009*\"light\"'),\n",
              " (4,\n",
              "  '0.090*\"ax\" + 0.077*\"max\" + 0.018*\"di_di\" + 0.015*\"tumor\" + 0.012*\"homosexual\" + 0.011*\"gay\" + 0.009*\"taste\" + 0.008*\"liar\" + 0.007*\"marry\" + 0.006*\"homosexuality\"'),\n",
              " (5,\n",
              "  '0.017*\"government\" + 0.013*\"people\" + 0.012*\"gun\" + 0.011*\"state\" + 0.010*\"kill\" + 0.008*\"year\" + 0.007*\"public\" + 0.007*\"attack\" + 0.007*\"patient\" + 0.007*\"country\"'),\n",
              " (6,\n",
              "  '0.036*\"line\" + 0.017*\"thank\" + 0.015*\"host\" + 0.013*\"use\" + 0.013*\"problem\" + 0.011*\"get\" + 0.011*\"work\" + 0.011*\"need\" + 0.010*\"system\" + 0.010*\"window\"'),\n",
              " (7,\n",
              "  '0.033*\"would\" + 0.027*\"write\" + 0.018*\"article\" + 0.017*\"line\" + 0.016*\"know\" + 0.016*\"think\" + 0.016*\"make\" + 0.014*\"be\" + 0.012*\"may\" + 0.012*\"say\"'),\n",
              " (8,\n",
              "  '0.021*\"evidence\" + 0.013*\"believe\" + 0.013*\"reason\" + 0.010*\"faith\" + 0.010*\"say\" + 0.010*\"sense\" + 0.009*\"claim\" + 0.009*\"exist\" + 0.009*\"law\" + 0.008*\"physical\"'),\n",
              " (9,\n",
              "  '0.020*\"key\" + 0.018*\"program\" + 0.018*\"file\" + 0.013*\"information\" + 0.012*\"use\" + 0.010*\"system\" + 0.009*\"available\" + 0.008*\"source\" + 0.008*\"image\" + 0.008*\"include\"')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipvqStGNumyd"
      },
      "source": [
        "Мы дошли до определения списка слов в топиках!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOFFDPdhiTLU"
      },
      "source": [
        "topic_dict = {}\n",
        "for topic in list(t):\n",
        "    topic = tuple(topic)\n",
        "    new_top = {}\n",
        "    for word in topic[1].split(' + '):\n",
        "        word = word.split('*')\n",
        "        new_top[word[1].strip('\\\"\\\"')] = float(word[0])\n",
        "    topic_dict[topic[0]] = new_top"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpZ7Kf0ziUaS",
        "outputId": "38202a79-6433-48e7-9673-be681b5c9775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "topic_dict[0]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'game': 0.026,\n",
              " 'good': 0.009,\n",
              " 'hit': 0.009,\n",
              " 'last': 0.01,\n",
              " 'play': 0.02,\n",
              " 'player': 0.014,\n",
              " 'run': 0.01,\n",
              " 'team': 0.028,\n",
              " 'win': 0.018,\n",
              " 'year': 0.027}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1tha5Jpu3-4"
      },
      "source": [
        "Это был список слов для топика спорт? Как мило"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBDKOt0DiYIe"
      },
      "source": [
        "text_topics = []\n",
        "for text in data_lemmatized:\n",
        "    count = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "    for word in text:\n",
        "        for topic, lemmas in topic_dict.items():\n",
        "            for lemm in lemmas:\n",
        "                if lemm == word:\n",
        "                    count[topic] += lemmas[lemm]\n",
        "    text_topics.append(count.index(max(count)))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh8bNBg8ieP4",
        "outputId": "6814480e-0f58-435a-84ee-40aaa21e0846",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "if len(text_topics)==len(data_lemmatized):\n",
        "  print('Carry on')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carry on\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCSJINvqu8fr"
      },
      "source": [
        "Порядок, ничего не потерялось"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ytsa5H_kwc_w"
      },
      "source": [
        "## ТФ-ИДФ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sc3mLX-jSsJ"
      },
      "source": [
        "df_prefinal = pd.DataFrame()\n",
        "df_prefinal['texts'] = df['content']\n",
        "df_prefinal['lemmas'] = data_lemmatized\n",
        "df_prefinal['topics'] = text_topics\n",
        "df_prefinal['ind'] = [x for x in range(0,11314)]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vn7qK1Vja_w",
        "outputId": "4b0acb7f-936f-4628-ad6a-0032fe3f6a8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "df_prefinal.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>lemmas</th>\n",
              "      <th>topics</th>\n",
              "      <th>ind</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
              "      <td>[where, thing, car, nntp_poste, host, park, li...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
              "      <td>[poll, final, call, summary, final, call, cloc...</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
              "      <td>[engineering, computer, network, distribution_...</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
              "      <td>[division, line, host, write, write, article, ...</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
              "      <td>[question, distribution, article, write, clear...</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               texts  ... ind\n",
              "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...  ...   0\n",
              "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...  ...   1\n",
              "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...  ...   2\n",
              "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...  ...   3\n",
              "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...  ...   4\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsp8ueUovABB"
      },
      "source": [
        "Как красиво! У нас есть варианты топиков, леммы, рабочая модель!\n",
        "\n",
        "по такой радости выведем сообщения из первого топика"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8su3wLljero"
      },
      "source": [
        "df_1 = df_prefinal[df_prefinal['topics'] == 0]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq6TB8E4jl-g",
        "outputId": "d82346a3-48c9-4b6b-bcf8-5c18434cf57a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "df_1.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>lemmas</th>\n",
              "      <th>topics</th>\n",
              "      <th>ind</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...</td>\n",
              "      <td>[insurance, rate, performance, car, line, late...</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>From: paul@csd4.csd.uwm.edu (Paul R Krueger)\\n...</td>\n",
              "      <td>[rock, division, line, nntp_poste, host, origi...</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>From: 18084TM@msu.edu (Tom)\\nSubject: Golden &amp;...</td>\n",
              "      <td>[age, added_forwarde, organization, distributi...</td>\n",
              "      <td>0</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>From: seth@cbnewsh.cb.att.com (peter.r.clark.....</td>\n",
              "      <td>[flyer, year, big, worst_opinion, organization...</td>\n",
              "      <td>0</td>\n",
              "      <td>208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>From: dpeterik@iastate.edu (Dan Peterik)\\nSubj...</td>\n",
              "      <td>[line, write, know, brewer, s, back, team, mas...</td>\n",
              "      <td>0</td>\n",
              "      <td>256</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 texts  ...  ind\n",
              "17   From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...  ...   17\n",
              "43   From: paul@csd4.csd.uwm.edu (Paul R Krueger)\\n...  ...   43\n",
              "49   From: 18084TM@msu.edu (Tom)\\nSubject: Golden &...  ...   49\n",
              "208  From: seth@cbnewsh.cb.att.com (peter.r.clark.....  ...  208\n",
              "256  From: dpeterik@iastate.edu (Dan Peterik)\\nSubj...  ...  256\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eUCjPRXjpdv",
        "outputId": "f3c03592-1967-4a89-83fd-f26cf210bc09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df_1['lemmas'].tolist()[0]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['insurance',\n",
              " 'rate',\n",
              " 'performance',\n",
              " 'car',\n",
              " 'line',\n",
              " 'latech',\n",
              " 'newsreader_nnr',\n",
              " 'recently',\n",
              " 'post',\n",
              " 'article',\n",
              " 'ask',\n",
              " 'kind',\n",
              " 'rate',\n",
              " 'single',\n",
              " 'male',\n",
              " 'driver',\n",
              " 'yrs',\n",
              " 'old',\n",
              " 'pay',\n",
              " 'performance',\n",
              " 'car',\n",
              " 'here',\n",
              " 'summary',\n",
              " 'reply',\n",
              " 'receive',\n",
              " 'be',\n",
              " 'anymore',\n",
              " 'close',\n",
              " 'enough',\n",
              " 'twin',\n",
              " 'turbo',\n",
              " 'model',\n",
              " 'ticket',\n",
              " 'accident',\n",
              " 'take',\n",
              " 'defensive',\n",
              " 'driving',\n",
              " 'airbag',\n",
              " 'security',\n",
              " 'single',\n",
              " 'year',\n",
              " 'state',\n",
              " 'farm',\n",
              " 'insurance',\n",
              " 'include',\n",
              " 'additional',\n",
              " 'umbrella',\n",
              " 'policy',\n",
              " 'car',\n",
              " 'house',\n",
              " 'base',\n",
              " 'policy',\n",
              " 'standard',\n",
              " 'policy',\n",
              " 'require',\n",
              " 'defensive',\n",
              " 'drive',\n",
              " 'course',\n",
              " 'less',\n",
              " 'buy',\n",
              " 'car',\n",
              " 'company',\n",
              " 'never',\n",
              " 'accident',\n",
              " 'ticket',\n",
              " 'year',\n",
              " 'quote',\n",
              " 'hope',\n",
              " 'help',\n",
              " 'remember',\n",
              " 'name',\n",
              " 'correctly',\n",
              " 'ask',\n",
              " 'insurance',\n",
              " 'performance',\n",
              " 'car',\n",
              " 'well',\n",
              " 'last',\n",
              " 'year',\n",
              " 'similar',\n",
              " 'situation',\n",
              " 'buy',\n",
              " 'car',\n",
              " 'make',\n",
              " 'inquiry',\n",
              " 'age',\n",
              " 'car',\n",
              " 'drive',\n",
              " 'record',\n",
              " 'turn',\n",
              " 'may',\n",
              " 'insurance',\n",
              " 'go',\n",
              " 'mos',\n",
              " 'also',\n",
              " 'be',\n",
              " 'single',\n",
              " 'incur',\n",
              " 'high',\n",
              " 'rate',\n",
              " 'company',\n",
              " 'have',\n",
              " 'get',\n",
              " 'couple',\n",
              " 'friend',\n",
              " 'pay',\n",
              " 'different',\n",
              " 'in',\n",
              " 'company',\n",
              " 'also',\n",
              " 'maybe',\n",
              " 'be',\n",
              " 'lucky',\n",
              " 'hope',\n",
              " 'info',\n",
              " 'help',\n",
              " 'group',\n",
              " 'be',\n",
              " 'thunderbird',\n",
              " 'sc',\n",
              " 'never',\n",
              " 'make',\n",
              " 'claim',\n",
              " 'insurance',\n",
              " 'though',\n",
              " 'hit',\n",
              " 'several',\n",
              " 'time',\n",
              " 'negligent',\n",
              " 'driver',\n",
              " 'could',\n",
              " 'see',\n",
              " 'stop',\n",
              " 'sign',\n",
              " 'fiddle',\n",
              " 'radio',\n",
              " 'move',\n",
              " 'violation',\n",
              " 'last',\n",
              " 'month',\n",
              " 'go',\n",
              " 'failure',\n",
              " 'clear',\n",
              " 'intersection',\n",
              " 'still',\n",
              " 'say',\n",
              " 'damn',\n",
              " 'light',\n",
              " 'yellow',\n",
              " 'one',\n",
              " 'go',\n",
              " 'go',\n",
              " 'record',\n",
              " 'rate',\n",
              " 'state',\n",
              " 'passive',\n",
              " 'restraint',\n",
              " 'deduction',\n",
              " 'liability',\n",
              " 'deductible',\n",
              " 'comprehensive',\n",
              " 'deductible',\n",
              " 'collision',\n",
              " 'roughly',\n",
              " 'year',\n",
              " 'pay',\n",
              " 'year',\n",
              " 'disclaimer',\n",
              " 'be',\n",
              " 'engineer',\n",
              " 'play',\n",
              " 'work',\n",
              " 'hell',\n",
              " 'thing',\n",
              " 'kill',\n",
              " 'man',\n",
              " 'take',\n",
              " 'away',\n",
              " 's',\n",
              " 'ever',\n",
              " 'go',\n",
              " 'age',\n",
              " 'group',\n",
              " 'experience',\n",
              " 'may',\n",
              " 'interesting',\n",
              " 'own',\n",
              " 'decide',\n",
              " 'buy',\n",
              " 'gift',\n",
              " 'exotic',\n",
              " 'car',\n",
              " 'front',\n",
              " 'runner',\n",
              " 'include',\n",
              " 'model',\n",
              " 'year',\n",
              " 'narrow',\n",
              " 'like',\n",
              " 'simplicity',\n",
              " 'handling',\n",
              " 'snob',\n",
              " 'appeal',\n",
              " 'drive',\n",
              " 'turbo',\n",
              " 'less',\n",
              " 'money',\n",
              " 'feature',\n",
              " 'performance',\n",
              " 'almost',\n",
              " 'personal',\n",
              " 'luxury',\n",
              " 'car',\n",
              " 'well',\n",
              " 'acceleration',\n",
              " 'high',\n",
              " 'top',\n",
              " 'speed',\n",
              " 'almost',\n",
              " 'ready',\n",
              " 'give',\n",
              " 'buying',\n",
              " 'impulse',\n",
              " 'decide',\n",
              " 'stop',\n",
              " 'insurance',\n",
              " 'agent',\n",
              " 'office',\n",
              " 'way',\n",
              " 'ask',\n",
              " 'would',\n",
              " 'happen',\n",
              " 'rate',\n",
              " 'car',\n",
              " 'buy',\n",
              " 'rate',\n",
              " 'consider',\n",
              " 'year',\n",
              " 'rate',\n",
              " 'safe',\n",
              " 'car',\n",
              " 'slight',\n",
              " 'increase',\n",
              " 'car',\n",
              " 'year',\n",
              " 'new',\n",
              " 'low',\n",
              " 'risk',\n",
              " 'division',\n",
              " 'continue',\n",
              " 'handle',\n",
              " 'account',\n",
              " 'buy',\n",
              " 'change',\n",
              " 'standard',\n",
              " 'high',\n",
              " 'rate',\n",
              " 'company',\n",
              " 'rate',\n",
              " 'double',\n",
              " 'go',\n",
              " 'story',\n",
              " 'well',\n",
              " 'cover',\n",
              " 'rest',\n",
              " 'year',\n",
              " 'much',\n",
              " 'faster',\n",
              " 'actually',\n",
              " 'fast',\n",
              " 'standard',\n",
              " 'make',\n",
              " 'sense',\n",
              " 'book',\n",
              " 'say',\n",
              " 'insure',\n",
              " 'corvette',\n",
              " 'reason',\n",
              " 'underwriter',\n",
              " 'consider',\n",
              " 'supra',\n",
              " 'driver',\n",
              " 'traditional',\n",
              " 'conservative',\n",
              " 'eventually',\n",
              " 'go',\n",
              " 'number',\n",
              " 'reason',\n",
              " 'porsche',\n",
              " 'dealer',\n",
              " 'nice',\n",
              " 'salesman',\n",
              " 'get',\n",
              " 'interested',\n",
              " 'tough',\n",
              " 'high',\n",
              " 'pressure',\n",
              " 'guy',\n",
              " 'back',\n",
              " 'room',\n",
              " 'equal',\n",
              " 'monthly',\n",
              " 'payment',\n",
              " 'would',\n",
              " 'take',\n",
              " 'year',\n",
              " 'longer',\n",
              " 'pay',\n",
              " 'porsche',\n",
              " 'high',\n",
              " 'insurance',\n",
              " 'conclude',\n",
              " 'high',\n",
              " 'insurance',\n",
              " 'relate',\n",
              " 'probability',\n",
              " 'auto',\n",
              " 'theft',\n",
              " 'everyone',\n",
              " 'entitle',\n",
              " 'opinion',\n",
              " 'imagination',\n",
              " 'important',\n",
              " 'knowledge',\n",
              " 'live',\n",
              " 'idaho',\n",
              " 'many',\n",
              " 'year',\n",
              " 'buy',\n",
              " 'insurance',\n",
              " 'year',\n",
              " 'turn',\n",
              " 'immediately',\n",
              " 'drop',\n",
              " 'year',\n",
              " 'accident',\n",
              " 'strictly',\n",
              " 'age',\n",
              " 'change',\n",
              " 'rate',\n",
              " 'stay',\n",
              " 'pretty',\n",
              " 'much',\n",
              " 'sell',\n",
              " 'car',\n",
              " 'pickup',\n",
              " 'year',\n",
              " 'less',\n",
              " 'real',\n",
              " 'amazing',\n",
              " 'thing',\n",
              " 'wake',\n",
              " 'age',\n",
              " 'feel',\n",
              " 'much',\n",
              " 'responsible',\n",
              " 'information',\n",
              " 'single',\n",
              " 'move',\n",
              " 'violation',\n",
              " 'year',\n",
              " 'let',\n",
              " 'see',\n",
              " 'be',\n",
              " 'single',\n",
              " 'male',\n",
              " 'clean',\n",
              " 'driving',\n",
              " 'record',\n",
              " 'pay',\n",
              " 'year',\n",
              " 'good',\n",
              " 'deal',\n",
              " 'ask',\n",
              " 'think',\n",
              " 'get',\n",
              " 'talon',\n",
              " 'think',\n",
              " 'insurance',\n",
              " 'high',\n",
              " 'turbo',\n",
              " 'sport',\n",
              " 'car',\n",
              " 'clean',\n",
              " 'record',\n",
              " 'small',\n",
              " 'town',\n",
              " 'around',\n",
              " 'year',\n",
              " 'age',\n",
              " 'nearby',\n",
              " 'city',\n",
              " 'rate',\n",
              " 'higher',\n",
              " 'have',\n",
              " 'get',\n",
              " 'insure',\n",
              " 'protege',\n",
              " 'year',\n",
              " 'year',\n",
              " 'old',\n",
              " 'state',\n",
              " 'insurance',\n",
              " 'state',\n",
              " 'farm',\n",
              " 'info',\n",
              " 'car',\n",
              " 'co',\n",
              " 'insurance',\n",
              " 'yearly',\n",
              " 'insurance',\n",
              " 'age',\n",
              " 'date',\n",
              " 'license',\n",
              " 'mountain_view',\n",
              " 'move',\n",
              " 'violation',\n",
              " 'hope',\n",
              " 'help',\n",
              " 'post',\n",
              " 'summary',\n",
              " 'possible',\n",
              " 'vijay',\n",
              " 'email',\n",
              " 'single',\n",
              " 'year',\n",
              " 'old',\n",
              " 'turbo',\n",
              " 'full',\n",
              " 'cover',\n",
              " 'reasonable',\n",
              " 'liability',\n",
              " 'ticket',\n",
              " 'violation',\n",
              " 'accident',\n",
              " 'knock',\n",
              " 'wood',\n",
              " 'mass',\n",
              " 'thing',\n",
              " 'make',\n",
              " 'huge',\n",
              " 'difference',\n",
              " 'mass',\n",
              " 'town',\n",
              " 'live',\n",
              " 'be',\n",
              " 'personally',\n",
              " 'good',\n",
              " 'town',\n",
              " 'reasonable',\n",
              " 'distance',\n",
              " 'move',\n",
              " 'best',\n",
              " 'would',\n",
              " 'go',\n",
              " 'move',\n",
              " 'bad',\n",
              " 'would',\n",
              " 'also',\n",
              " 'accident',\n",
              " 'couple',\n",
              " 'ticket',\n",
              " 'would',\n",
              " 'probably',\n",
              " 'add',\n",
              " 'year',\n",
              " 'old',\n",
              " 'ticket',\n",
              " 'go',\n",
              " 'record',\n",
              " 'year',\n",
              " 'full',\n",
              " 'coverage',\n",
              " 'state',\n",
              " 'farm',\n",
              " 'get',\n",
              " 'small',\n",
              " 'discount',\n",
              " 'alarm',\n",
              " 'system',\n",
              " 'year',\n",
              " 'live',\n",
              " 'actually',\n",
              " 'live',\n",
              " 'city',\n",
              " 'price',\n",
              " 'would',\n",
              " 'year',\n",
              " 'be',\n",
              " 'case',\n",
              " 'be',\n",
              " 'interested',\n",
              " 'be',\n",
              " 'insure',\n",
              " 'month',\n",
              " 's',\n",
              " 'personal',\n",
              " 'total',\n",
              " 'property',\n",
              " 'deductible',\n",
              " 'glass',\n",
              " 'towing',\n",
              " 'state',\n",
              " 'farm',\n",
              " 'drive',\n",
              " 'less',\n",
              " 'year',\n",
              " 'think',\n",
              " 'seriously',\n",
              " 'rip',\n",
              " 'performance',\n",
              " 'car',\n",
              " 'list',\n",
              " 'record',\n",
              " 'clean',\n",
              " 'pay',\n",
              " 'try',\n",
              " 'call',\n",
              " 'insurance',\n",
              " 'dealer',\n",
              " 'could',\n",
              " 'find',\n",
              " 'rate',\n",
              " 'suppose',\n",
              " 'standardize',\n",
              " 'have',\n",
              " 'find',\n",
              " 'place',\n",
              " 'initially',\n",
              " 'call',\n",
              " 'give',\n",
              " 'ridiculously',\n",
              " 'high',\n",
              " 'hit',\n",
              " 'much',\n",
              " 'low',\n",
              " 'also',\n",
              " 'change',\n",
              " 'insurance_companie',\n",
              " 'rate',\n",
              " 'go',\n",
              " 'renewal',\n",
              " 'accident',\n",
              " 'ticket',\n",
              " 'car',\n",
              " 'get',\n",
              " 'old',\n",
              " 'maintain',\n",
              " 'low',\n",
              " 'rate',\n",
              " 'always',\n",
              " 'careful',\n",
              " 'come',\n",
              " 'insurance_companies',\n",
              " 'serge']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE6-9iGXvOg6"
      },
      "source": [
        "Звучит как правдоподобный вариант слов, по которым можно ориентироваться, чтобы спихать куда надо объекты про экономику"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL0zHqHgjtGX"
      },
      "source": [
        "def findwords(vect, words):\n",
        "    sorted_w = np.argsort(vect.data)[:-6:-1]\n",
        "    return words[vect.indices[sorted_w]]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAKD_t7Qj02m"
      },
      "source": [
        "all_topics = {}\n",
        "for i in range(10):\n",
        "    list_text = []\n",
        "    dict_of_topic = {}\n",
        "    df_1 = df_prefinal[df_prefinal['topics'] == i]\n",
        "    lemmas = df_1['lemmas'].tolist()\n",
        "    inds = df_1['ind'].tolist()\n",
        "    for num, t in enumerate(inds):\n",
        "        dict_of_topic[t] = lemmas[num]\n",
        "        list_text.append(' '.join(lemmas[num]))\n",
        "    vectors = vectorizer.fit_transform(list_text)\n",
        "    feature_names = np.array(vectorizer.get_feature_names())\n",
        "    #dense = vectors.todense()\n",
        "    #denselist = dense.tolist()\n",
        "    #df = pd.DataFrame(denselist, columns=feature_names)\n",
        "    3#for text in df.index.tolist():\n",
        "        #a = df[df[index] == text].tolist\n",
        "\n",
        "    for index_lemm, l in enumerate(lemmas):\n",
        "        #tfidf_dict = {}\n",
        "        text_vect = vectors[index_lemm, :]\n",
        "        top_words = findwords(text_vect, feature_names)\n",
        "        all_topics[inds[index_lemm]] = top_words\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4KxaI2kj4DQ",
        "outputId": "00521285-10e1-42cc-ca0a-53e01db436d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "list(all_topics[2])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['display', 'powerbook', 'machine', 'bunch', 'disk']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WsJvKvlkDuV"
      },
      "source": [
        "topics_list = []\n",
        "for key in range(0, 11314):\n",
        "    topics_list.append(all_topics[key])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVt1qiMykEZW"
      },
      "source": [
        "df_prefinal['topwords'] = topics_list"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO9GICVKkHgp",
        "outputId": "99799706-0c44-4edd-ca26-ed4d67f81e9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "df_prefinal"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>lemmas</th>\n",
              "      <th>topics</th>\n",
              "      <th>ind</th>\n",
              "      <th>topwords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
              "      <td>[where, thing, car, nntp_poste, host, park, li...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>[door, car, where, enlighten, funky]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
              "      <td>[poll, final, call, summary, final, call, cloc...</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>[poll, clock, final, upgrade, add]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
              "      <td>[engineering, computer, network, distribution_...</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>[display, powerbook, machine, bunch, disk]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
              "      <td>[division, line, host, write, write, article, ...</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>[division, quadrilateral, chip, weitek, winter]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
              "      <td>[question, distribution, article, write, clear...</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>[error, warn, bug, memory, waivere]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11309</th>\n",
              "      <td>From: jim.zisfein@factory.com (Jim Zisfein) \\n...</td>\n",
              "      <td>[scan, city, reply, line, consultation, cheap,...</td>\n",
              "      <td>7</td>\n",
              "      <td>11309</td>\n",
              "      <td>[patient, tumor, diagnosis, dn, scan]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11310</th>\n",
              "      <td>From: ebodin@pearl.tufts.edu\\nSubject: Screen ...</td>\n",
              "      <td>[screen, medford, old, problem, screen, blank,...</td>\n",
              "      <td>1</td>\n",
              "      <td>11310</td>\n",
              "      <td>[screen, blank, wire, new, board]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11311</th>\n",
              "      <td>From: westes@netcom.com (Will Estes)\\nSubject:...</td>\n",
              "      <td>[este, mount, mail, group, line, instal, try, ...</td>\n",
              "      <td>6</td>\n",
              "      <td>11311</td>\n",
              "      <td>[cpu, mount, este, weight, cool]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11312</th>\n",
              "      <td>From: steve@hcrlgw (Steven Collins)\\nSubject: ...</td>\n",
              "      <td>[line, article, write, boy, embarasse, trivial...</td>\n",
              "      <td>7</td>\n",
              "      <td>11312</td>\n",
              "      <td>[point, space, farin, specifie, embarasse]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11313</th>\n",
              "      <td>From: gunning@cco.caltech.edu (Kevin J. Gunnin...</td>\n",
              "      <td>[steal, organization, line, distribution_usa, ...</td>\n",
              "      <td>6</td>\n",
              "      <td>11313</td>\n",
              "      <td>[steal, kjg, cbr, baby, rider]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11314 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   texts  ...                                         topwords\n",
              "0      From: lerxst@wam.umd.edu (where's my thing)\\nS...  ...             [door, car, where, enlighten, funky]\n",
              "1      From: guykuo@carson.u.washington.edu (Guy Kuo)...  ...               [poll, clock, final, upgrade, add]\n",
              "2      From: twillis@ec.ecn.purdue.edu (Thomas E Will...  ...       [display, powerbook, machine, bunch, disk]\n",
              "3      From: jgreen@amber (Joe Green)\\nSubject: Re: W...  ...  [division, quadrilateral, chip, weitek, winter]\n",
              "4      From: jcm@head-cfa.harvard.edu (Jonathan McDow...  ...              [error, warn, bug, memory, waivere]\n",
              "...                                                  ...  ...                                              ...\n",
              "11309  From: jim.zisfein@factory.com (Jim Zisfein) \\n...  ...            [patient, tumor, diagnosis, dn, scan]\n",
              "11310  From: ebodin@pearl.tufts.edu\\nSubject: Screen ...  ...                [screen, blank, wire, new, board]\n",
              "11311  From: westes@netcom.com (Will Estes)\\nSubject:...  ...                 [cpu, mount, este, weight, cool]\n",
              "11312  From: steve@hcrlgw (Steven Collins)\\nSubject: ...  ...       [point, space, farin, specifie, embarasse]\n",
              "11313  From: gunning@cco.caltech.edu (Kevin J. Gunnin...  ...                   [steal, kjg, cbr, baby, rider]\n",
              "\n",
              "[11314 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH7s3g5Rv1yy"
      },
      "source": [
        "Мы рассортировали все по темам!\n",
        "Вуаля"
      ]
    }
  ]
}