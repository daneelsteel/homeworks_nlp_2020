{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X6Ctpz7uq6nQ"
   },
   "source": [
    "# Генсим и остальные неприятности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wSaaJX3XrBAt"
   },
   "source": [
    "## Импорты и подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "используемые данные: наш семинар, туториалы на медиуме (https://medium.com/@kurtsenol21/topic-modeling-lda-mallet-implementation-in-python-part-1-c493a5297ad2 - зачем-то же мне нужна на него подписка), молитвы древним богам, точно не домашки никаких из моих сокурсников"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "первым шагом в одной ячейке и импортируем все библиотеки, и сразу стягиваем из них все, что нам нужно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "dZwU9jJWfDXz",
    "outputId": "42b399e0-1b03-4a81-e49c-6f3500a45b69"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Эрнеста\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk; nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtDnIO6yrImz"
   },
   "source": [
    "ознакомимся с нашим датасетом - загрузим его в панды, по красивой пандовской традиции всяких датасайентистов назовем датафреймом.\n",
    "\n",
    "что у нас в его верхушке?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "KwhwjM_8gDkC",
    "outputId": "8cc859b5-4800-43e7-a8af-ab998eee1b4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rec.autos' 'comp.sys.mac.hardware' 'comp.graphics' 'sci.space'\n",
      " 'talk.politics.guns' 'sci.med' 'comp.sys.ibm.pc.hardware'\n",
      " 'comp.os.ms-windows.misc' 'rec.motorcycles' 'talk.religion.misc'\n",
      " 'misc.forsale' 'alt.atheism' 'sci.electronics' 'comp.windows.x'\n",
      " 'rec.sport.hockey' 'rec.sport.baseball' 'soc.religion.christian'\n",
      " 'talk.politics.mideast' 'talk.politics.misc' 'sci.crypt']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  target  \\\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...       7   \n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...       4   \n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4   \n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1   \n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14   \n",
       "\n",
       "            target_names  \n",
       "0              rec.autos  \n",
       "1  comp.sys.mac.hardware  \n",
       "2  comp.sys.mac.hardware  \n",
       "3          comp.graphics  \n",
       "4              sci.space  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#это было у нас в семинаре, да и в любом курсе по нейросетям или датасайенсу\n",
    "df = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
    "print(df.target_names.unique())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ti5mWKT_wIUY"
   },
   "source": [
    "## Очистка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiV5DTxOr9UG"
   },
   "source": [
    "Почистим эти данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "uFdEZZ_PgaML",
    "outputId": "58379751-03e0-4f6c-c4ae-97d486781294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From: (wheres my thing) Subject: WHAT car is this!? Nntp-Posting-Host: '\n",
      " 'rac3.wam.umd.edu Organization: University of Maryland, College Park Lines: '\n",
      " '15 I was wondering if anyone out there could enlighten me on this car I saw '\n",
      " 'the other day. It was a 2-door sports car, looked to be from the late 60s/ '\n",
      " 'early 70s. It was called a Bricklin. The doors were really small. In '\n",
      " 'addition, the front bumper was separate from the rest of the body. This is '\n",
      " 'all I know. If anyone can tellme a model name, engine specs, years of '\n",
      " 'production, where this car is made, history, or whatever info you have on '\n",
      " 'this funky looking car, please e-mail. Thanks, - IL ---- brought to you by '\n",
      " 'your neighborhood Lerxst ---- ']\n"
     ]
    }
   ],
   "source": [
    "#это было у нас чуть ли не со второго курса - и да, в семинаре\n",
    "data = df.content.values.tolist()\n",
    "\n",
    "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
    "\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "\n",
    "pprint(data[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOZgSecUsd1-"
   },
   "source": [
    "парсим предложения до уровня слов, которые можно будет скормить препроцессингу генсима"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "3KXVcCMmgiKt",
    "outputId": "de6996d8-48a4-440f-b131-0b86b5077fe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['from', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp', 'posting', 'host', 'rac', 'wam', 'umd', 'edu', 'organization', 'university', 'of', 'maryland', 'college', 'park', 'lines', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front', 'bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']]\n"
     ]
    }
   ],
   "source": [
    "#было в семинаре\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuaJLwxkwO8I"
   },
   "source": [
    "## Генсим"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pk0UD3H_sxpx"
   },
   "source": [
    "Мы дошли до генсима! Пойдем попросим его скрафтить биграммы и триграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "fBNklOBEgmPm",
    "outputId": "edb49b84-08ef-4c52-94ce-642af8f2080f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp_posting_host', 'rac_wam_umd_edu', 'organization', 'university', 'of', 'maryland_college_park', 'lines', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front_bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']\n"
     ]
    }
   ],
   "source": [
    "#было в семинаре! а уж откуда оно в семинаре, одним древним богам ведомо\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100)\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJ18G-zMs3G8"
   },
   "source": [
    "Теперь создадим функции для обращения к генсиму"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ой, а это забавно - это на медиуме было, ссылочка в первой ячейке. \n",
    "#Ну, и по традиции - и у нас в семинаре, правда, в разложенном на разные функции виде\n",
    "def process_words(texts, stop_words=stop_words, allowed_tags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \n",
    "    texts = [[word for word in simple_preprocess(str(doc), deacc=True, min_len=3) if word not in stop_words] for doc in texts]\n",
    "    \n",
    "    texts = [bigram_mod[doc] for doc in texts]\n",
    "    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "    \n",
    "    texts_out = []\n",
    "    \n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_tags])\n",
    "    \n",
    "    texts_out = [[word for word in simple_preprocess(str(doc), deacc=True, min_len=3) if word not in stop_words] for doc in texts_out]    \n",
    "    \n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "1JxxM8i7gxR2",
    "outputId": "48d17ad3-9bdb-4a78-f573-2a29458b9668"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['thing', 'car', 'line', 'wonder', 'could', 'enlighten', 'car', 'see', 'day', 'door', 'sport', 'car', 'look', 'late', 'early', 'call', 'door', 'really', 'small', 'addition', 'separate', 'rest', 'body', 'know', 'model', 'name', 'engine', 'spec', 'year', 'production', 'car', 'make', 'history', 'info', 'funky', 'look', 'car', 'mail', 'thank', 'bring', 'neighborhood', 'lerxst']]\n"
     ]
    }
   ],
   "source": [
    "texts = process_words(data_words)\n",
    "print(texts[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocabulary Size: 38795\n"
     ]
    }
   ],
   "source": [
    "#из семинара\n",
    "id2word = corpora.Dictionary(texts)\n",
    "print('Total Vocabulary Size:', len(id2word))\n",
    "\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#а вы мне сильно по башке надаете, если я последую дальше по статье, а не по семинару?\n",
    "#мне тоже нравится идея отфильтровать самые частые и самые редкие слова, чтобы не забивать модель малозначимой информацией\n",
    "dict_corpus = {}\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "  for idx, freq in corpus[i]:\n",
    "    if id2word[idx] in dict_corpus:\n",
    "      dict_corpus[id2word[idx]] += freq\n",
    "    else:\n",
    "       dict_corpus[id2word[idx]] = freq\n",
    "       \n",
    "dict_df = pd.DataFrame.from_dict(dict_corpus, orient='index', columns=['freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x282d321cdc8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#как и идея глянуть на графике частотность, чтобы отсеять самые частые\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.distplot(dict_df['freq'], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>line</th>\n",
       "      <td>11518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>write</th>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>9541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say</th>\n",
       "      <td>7029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>6345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>5942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>5786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <td>5775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>5573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>5216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          freq\n",
       "line     11518\n",
       "write     9999\n",
       "would     9541\n",
       "say       7029\n",
       "know      6345\n",
       "people    5942\n",
       "make      5786\n",
       "article   5775\n",
       "think     5573\n",
       "get       5216"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_df.sort_values('freq', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocabulary Size: 38656\n"
     ]
    }
   ],
   "source": [
    "extension = dict_df[dict_df.freq>4000].index.tolist()\n",
    "# add high frequency words to stop words list\n",
    "stop_words.extend(extension)\n",
    "# rerun the process_words function\n",
    "texts = process_words(data_words)\n",
    "# recreate Dictionary\n",
    "id2word = corpora.Dictionary(texts)\n",
    "print('Total Vocabulary Size:', len(id2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocabulary Size: 6689\n"
     ]
    }
   ],
   "source": [
    "id2word.filter_extremes(no_below=10, no_above=0.5)\n",
    "print('Total Vocabulary Size:', len(id2word))\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем запустить маллет - вдруг именно у нас получится?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#это из туториалов по маллету\n",
    "import os\n",
    "os.environ['MALLET_HOME'] = 'C:/mallet-2.0.8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'C:/mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input C:\\Users\\BCD4~1\\AppData\\Local\\Temp\\d2fb3d_corpus.txt --output C:\\Users\\BCD4~1\\AppData\\Local\\Temp\\d2fb3d_corpus.mallet' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-2ef0b91caeec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#это из формулировки нашей домашки\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmallet_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:/mallet-2.0.8/bin/mallet'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mldamallet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLdaMallet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmallet_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Show Topics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\gensim\\models\\wrappers\\ldamallet.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mallet_path, corpus, num_topics, alpha, id2word, workers, prefix, optimize_interval, iterations, topic_threshold, random_seed)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_seed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfinferencer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\gensim\\models\\wrappers\\ldamallet.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, corpus)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m         \"\"\"\n\u001b[1;32m--> 272\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m         \u001b[0mcmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmallet_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' train-topics --input %s --num-topics %s  --alpha %s --optimize-interval %s '\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m             \u001b[1;34m'--num-threads %s --output-state %s --output-doc-topics %s --output-topic-keys %s '\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\gensim\\models\\wrappers\\ldamallet.py\u001b[0m in \u001b[0;36mconvert_input\u001b[1;34m(self, corpus, infer, serialize_corpus)\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mcmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcmd\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfcorpustxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfcorpusmallet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"converting temporary corpus to MALLET format with %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m         \u001b[0mcheck_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mcheck_output\u001b[1;34m(stdout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m   1930\u001b[0m             \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1931\u001b[0m             \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1932\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1933\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1934\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command 'C:/mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input C:\\Users\\BCD4~1\\AppData\\Local\\Temp\\d2fb3d_corpus.txt --output C:\\Users\\BCD4~1\\AppData\\Local\\Temp\\d2fb3d_corpus.mallet' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "#это из формулировки нашей домашки\n",
    "mallet_path = 'C:/mallet-2.0.8/bin/mallet'\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)\n",
    "\n",
    "# Show Topics\n",
    "pprint(ldamallet.show_topics(formatted=False))\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Факир был пьян, и фокус не удался. Даже если сделать все, что советует стаковерфлоу - изменить маллет.бат, натыкать его носом в конкретный путь до Джавы, вообще изменить расположение маллета - все равно все падает. Возвращаемся к обычному генсиму."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGomEMRxt4gj"
   },
   "source": [
    "А теперь создаем функцию, которая найдет нам лучшие параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "Va4T6Tb9hLlM"
   },
   "outputs": [],
   "source": [
    "#это же вроде очевидная функция?..\n",
    "#просто зациклить определение кохерентности, оставить лучший результат\n",
    "def choose_score(start, end, step, corpus, id2word, texts):\n",
    "    best_coh = 0\n",
    "    best_num = 0\n",
    "    for i in range(start, end, step):\n",
    "        lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=i, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "\n",
    "        coherence_lda_model = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "        coherence_lda = coherence_lda_model.get_coherence()\n",
    "        if coherence_lda > best_coh:\n",
    "            best_coh = coherence_lda\n",
    "            best_num = i\n",
    "            best_model = lda_model\n",
    "            print(best_coh, best_num)\n",
    "\n",
    "    return (best_coh, best_num, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "id": "RSwPQSGrhjCI",
    "outputId": "a2b6bf20-e327-4a97-962a-6932886c55a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44511491720100127 5\n",
      "0.490833259504702 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.490833259504702, 10, <gensim.models.ldamodel.LdaModel at 0x282ee71c5c8>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choose_score(5, 50, 5, corpus, id2word, texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8O3sXJxguGSJ"
   },
   "source": [
    "Сама функция для генсимовской модели! теперь с определенным нами лучшим числом групп"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "ydXtpz5Ch1PE"
   },
   "outputs": [],
   "source": [
    "#из семинара\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "doc_lda = lda_model[corpus]\n",
    "t = lda_model.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "7hvqiVpNh_kA",
    "outputId": "39a22c6d-02a4-49ea-96ef-8a2f03a60a7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.028*\"team\" + 0.027*\"year\" + 0.026*\"game\" + 0.020*\"play\" + 0.018*\"win\" + 0.014*\"player\" + 0.010*\"run\" + 0.010*\"last\" + 0.009*\"good\" + 0.009*\"hit\"'),\n",
       " (1,\n",
       "  '0.022*\"go\" + 0.015*\"time\" + 0.013*\"day\" + 0.012*\"come\" + 0.011*\"take\" + 0.011*\"back\" + 0.011*\"get\" + 0.009*\"say\" + 0.008*\"see\" + 0.008*\"first\"'),\n",
       " (2,\n",
       "  '0.014*\"space\" + 0.008*\"cost\" + 0.008*\"year\" + 0.007*\"high\" + 0.007*\"research\" + 0.007*\"low\" + 0.006*\"item\" + 0.006*\"also\" + 0.006*\"test\" + 0.005*\"large\"'),\n",
       " (3,\n",
       "  '0.033*\"car\" + 0.021*\"drive\" + 0.013*\"bike\" + 0.011*\"power\" + 0.011*\"wire\" + 0.011*\"slave\" + 0.010*\"reality\" + 0.009*\"speed\" + 0.009*\"engine\" + 0.009*\"light\"'),\n",
       " (4,\n",
       "  '0.090*\"ax\" + 0.077*\"max\" + 0.018*\"di_di\" + 0.015*\"tumor\" + 0.012*\"homosexual\" + 0.011*\"gay\" + 0.009*\"taste\" + 0.008*\"liar\" + 0.007*\"marry\" + 0.006*\"homosexuality\"'),\n",
       " (5,\n",
       "  '0.017*\"government\" + 0.013*\"people\" + 0.012*\"gun\" + 0.011*\"state\" + 0.010*\"kill\" + 0.008*\"year\" + 0.007*\"public\" + 0.007*\"attack\" + 0.007*\"patient\" + 0.007*\"country\"'),\n",
       " (6,\n",
       "  '0.036*\"line\" + 0.017*\"thank\" + 0.015*\"host\" + 0.013*\"use\" + 0.013*\"problem\" + 0.011*\"get\" + 0.011*\"work\" + 0.011*\"need\" + 0.010*\"system\" + 0.010*\"window\"'),\n",
       " (7,\n",
       "  '0.033*\"would\" + 0.027*\"write\" + 0.018*\"article\" + 0.017*\"line\" + 0.016*\"know\" + 0.016*\"think\" + 0.016*\"make\" + 0.014*\"be\" + 0.012*\"may\" + 0.012*\"say\"'),\n",
       " (8,\n",
       "  '0.021*\"evidence\" + 0.013*\"believe\" + 0.013*\"reason\" + 0.010*\"faith\" + 0.010*\"say\" + 0.010*\"sense\" + 0.009*\"claim\" + 0.009*\"exist\" + 0.009*\"law\" + 0.008*\"physical\"'),\n",
       " (9,\n",
       "  '0.020*\"key\" + 0.018*\"program\" + 0.018*\"file\" + 0.013*\"information\" + 0.012*\"use\" + 0.010*\"system\" + 0.009*\"available\" + 0.008*\"source\" + 0.008*\"image\" + 0.008*\"include\"')]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipvqStGNumyd"
   },
   "source": [
    "Мы дошли до определения списка слов в топиках!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "TOFFDPdhiTLU"
   },
   "outputs": [],
   "source": [
    "#довольно очевидный цикл, мы такие на втором курсе писали. Хотя меня печалит наличие двух циклов - на производительность плохо влияет.\n",
    "#если все будет сильно плохо, придется в колаб переходить\n",
    "topic_dict = {}\n",
    "for topic in list(t):\n",
    "    topic = tuple(topic)\n",
    "    new_top = {}\n",
    "    for word in topic[1].split(' + '):\n",
    "        word = word.split('*')\n",
    "        new_top[word[1].strip('\\\"\\\"')] = float(word[0])\n",
    "    topic_dict[topic[0]] = new_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "YpZ7Kf0ziUaS",
    "outputId": "38202a79-6433-48e7-9673-be681b5c9775"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'game': 0.026,\n",
       " 'good': 0.009,\n",
       " 'hit': 0.009,\n",
       " 'last': 0.01,\n",
       " 'play': 0.02,\n",
       " 'player': 0.014,\n",
       " 'run': 0.01,\n",
       " 'team': 0.028,\n",
       " 'win': 0.018,\n",
       " 'year': 0.027}"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_dict[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1tha5Jpu3-4"
   },
   "source": [
    "Это был список слов для топика спорт? Как мило"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "fBDKOt0DiYIe"
   },
   "outputs": [],
   "source": [
    "#это то, что нам предложили сделать в формулировке домашки\n",
    "text_topics = []\n",
    "for text in data_lemmatized:\n",
    "    count = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    for word in text:\n",
    "        for topic, lemmas in topic_dict.items():\n",
    "            for lemm in lemmas:\n",
    "                if lemm == word:\n",
    "                    count[topic] += lemmas[lemm]\n",
    "    text_topics.append(count.index(max(count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "uh8bNBg8ieP4",
    "outputId": "6814480e-0f58-435a-84ee-40aaa21e0846"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carry on\n"
     ]
    }
   ],
   "source": [
    "if len(text_topics)==len(texts):\n",
    "  print('Carry on')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCSJINvqu8fr"
   },
   "source": [
    "Из плохих новостей: я достаточно плохо понимаю, что делать с ТФ-ИДФ.\n",
    "Из хороших - я могу сказать, что такое coherence score!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coherence score это довольно интересный пайплайн для определения правильности найденного топика\n",
    "он состоит из четырех компонентов: сегментация, оценка вероятности, оценка подтвержденности и аггрегация всех предыдущих в одно число, вроде АУК или аккьюраси нейросетки, только более общо\n",
    "Сегментация это этап, в котором нам поступают топики всего текста, оценка вероятности происходит следом для каждого топика, потом мы проверяем, насколько мы уверены в каждом из них и насколько мы близки к правде, а потом аггрегатор своей функцией собирает результаты предыдущих трех этапов и выдает итоговое число"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
